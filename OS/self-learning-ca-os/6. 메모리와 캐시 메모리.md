# 메모리와 캐시 메모리

RAM에는 실행할 프로그램의 명령어와 데이터가 저장된다.

휘발되기 때문에 휘발성 저장 장치 (Volatile Memory)라고 한다.

전원이 꺼져도 저장된 내용이 유지되는 저장 장치는 비휘발성 저장장치(Non-Volatile Memory)라고 한다.

### RAM의 종류

- DRAM(Dynamic RAM)

데이터가 동적으로 변하는(사라지는)RAM을 의미한다.

`DRAM은 시간이 지나면 저장된 데이터가 점차 사라지는 RAM이다.`

DRAM은 데이터의 소멸을 막기위해 일정 주기로 데이터를 재활성화(다시 저장)해야한다.

이런 단점에도 불구하고 우리가 일반적으로 메모리로써 사용하는 RAM은 DRAM이다.

소비전력이 낮고, 저렴하고, 집적도가 높기에 대용량으로 설계하기 용이하기 때문이다.;

- SRAM(Static RAM)

시간이 지나도 저장된 데이터가 사라지지 않는다. 당연하게 주기적으로 데이터를 재활성화할 필요도 없다. 또한 SRAM은 DRAM보다 일반적으로 속도도 빠르다.

물론 전원을 끄면 저장된 내용은 사라진다.

SRAM은 DRAM보다 집적도가 낮고 소비 전력도 크며, 가격도 더 비싸다.

그래서 SRAM은 메모리가 아닌 ‘대용량으로 만들어질 필요는 없지만 속도가 빨라야하는 저장 장치에 사용된다.

`예시가, 캐시메모리다.`

- SDRAM(Synchronous Dynamic RAM)

클럭 신호와 동기화된, 발전된 형태의 DRAM이다.

클럭에 맞춰 동작하며 클럭마다 CPU와 정보를 주고 받을 수 있다.

- DDR SDRAM(Double Data Rate SDRAM)

최근 가장 흔히 사용되는 RAM이다.

DDR SDRAM은 대역폭을 넓혀 속도를 빠르게 만든 SDRAM이다.

여기서 대역폭(Data Rate)란?

데이터를 주고받는 길의 너비를 의미한다.

SDR(Single Data Rate) SDRAM에 비해 DDR SDRAM은 두 배의 대역폭으로 한 클럭당 두 번씩 CPU와 데이터를 주고받을 수 있다.

당연하게도 DDR SDRAM의 전송 속도가 두 배 가량 빠르다.

DDR2 SDRAM은 DDR SDRAM보다 대역폭이 두 배 넓다.

즉, SDR SDRAM보다는 너비가 네 배 넓은 도로와도 같다.

한 세대별로 대역폭이 두배 넓어진다.

즉, DDR3 는 DDR2보다 대역폭이 두 배 넓고, DDR4는 DDR3보다 두 배 넓다.

즉 SDR SDRAM보다 DDR4는 16배의 대역폭을 가진다.

## 메모리의 주소 공간

1. 물리 주소 : 메모리 하드웨어가 사용하는 주소

메모리가 사용하는 물리주소는 말 그대로 정보가 실제로 저장된 하드웨어 상의 주소를 의미한다.

1. 논리 주소 : CPU와 실행중인 프로그램이 사용하는 주소

CPU와 실행 중인 프로그램이 사용하는 논리주소 Logical Address는 실행 중인 프로그램 각각에게 부여된 0번지부터 시작되는 주소를 의미한다.

![Untitled](https://user-images.githubusercontent.com/70310271/210796340-c7225522-053b-4e87-9789-ddbe03661877.png)

- 왜 물리주소와 논리주소를 따로 나눌수 밖에 없었을까?

CPU와 메모리에 저장되어 실행중인 프로그램은 메모리 몇 번지에 무엇이 저장되어 있는지 다 알지 못한다.

프로그램을 실행할 때마다 메모리에 저장된 정보의 주소가 달라질 수 있기 때문이다.

메모장, 게임, 인터넷 브라우저는 모두 물리 주소가 아닌 0번지부터 시작하는 자신만을 위한 주소인 논리주소를 가지고 있다.

즉, 프로그램마다 같은 논리 주소가 얼마든지 있을 수 있다.

CPU는 이 논리주소를 받아들이고, 해석하고, 연산한다.

CPU가 메모리와 상호작용하려면 논리주소와 물리주소간의 변환이 이루어져야한다.

어떻게 논리 주소는 물리주소로 변환될까?

![Untitled 1](https://user-images.githubusercontent.com/70310271/210796449-f1e74b2c-8e8d-41de-a6dc-4adfdd74c9cf.png)

논리 주소와 물리 주소간의 변환은 CPU와 주소 버스 사이에 위치한 메모리 관리 장치(MMU : Memory Management Unit)라는 하드웨어에 의해 수행된다.

MMU는 CPU가 발생시킨 논리주소에 베이스 레지스터 값을 더하여 논리 주소를 물리주소로 변환한다.

![Untitled 2](https://user-images.githubusercontent.com/70310271/210796472-a5d060bd-99f5-4939-90cd-1f502fb54106.png)

베이스 레지스터는 프로그램의 가장 작은 물리 주소, 즉 프로그램의 첫 물리 주소를 저장하는 셈이고, 논리주소는 프로그램의 시작점으로부터 떨어진 거리인 셈이다.

### 메모리 보호 기법

![Untitled 3](https://user-images.githubusercontent.com/70310271/210796494-a63384c1-2cef-4bbd-be1d-87d5e44a6984.png)

자기 자신의 프로그램보다 높거나 낮은 주소를 참조하려고 하면 당연히 안된다.

논리 주소 범위를 벗어나는 명령어 실행을 방지하고 실행 중인 프로그램이 다른 프로그램에 영향을 받지 않도록 보호할 방법이 필요하다.

`이는 한계 레지스터(Limit Register)가 담당한다.`

베이스 레지스터가 실행중인 프로그램의 가장 작은 물리 주소를 저장한다면, 한계 레지스터는 논리주소의 최대 크기를 저장한다.

![Untitled 4](https://user-images.githubusercontent.com/70310271/210796522-109d1ca1-831b-4f93-9205-9d3a1f4fa8a3.png)

CPU는 메모리에 접근하기 전에 접근하고자 하는 논리 주소가 한계 레지스터보다 작은지를 항상 검사한다.

만약 CPU가 한계 레지스터보다 높은 논리 주소에 접근하려고 하면 인터럽트(트랩)을 발생시켜 실행을 중단한다.

논리 주소가 한계 레지스터보다 작은가?

NO → 인터럽트 발생

YES → 베이스 레지스터 + 논리주소 로 물리주소 접근.

### 캐시 메모리

CPU는 프로그램을 실행하는 과정에서 메모리에 저장된 데이터를 빈번하게 사용한다.

하지만 CPU가 메모리에 접근하는 시간은 CPU의 연산속도보다 느리다.

CPU가 연산을 빨리 한다 해도 메모리에 접근하는 시간이 느리면 CPU의 빠른 연산 속도는 의미가 없다.

이를 극복하기 위한 장치가 캐시 메모리다.

- 저장 장치 계층 구조 (Memory Hierarchy)

컴퓨터가 사용하는 저장 장치들은 CPU에 얼마나 가까운가를 기준으로 계층적으로 나타낼 수 있다.

![Untitled 5](https://user-images.githubusercontent.com/70310271/210796557-037f66c6-f822-4f79-9820-86549793dfcf.png)

CPU가 메모리에 접근하는 속도는 레지스터에 접근하는 속도보다 느리다.

캐시 메모리는 CPU와 메모리 사이에 위치하고, 레지스터보다 용량이 크고 메모리보다 빠른 SRAM 기반의 저장 장치이다.

캐시 메모리들은 CPU(코어)와 가까운 순서대로 계층을 구성한다.

코어와 가장 가까운 캐시 메모리를 L1(Level1) 캐시, L2(Level2)캐시, 그다음 가까운 캐시 메모리를 L3(Level3) 캐시라고 부른다.

일반적으로 L1 캐시와 L2 캐시는 코어 내부에, L3 캐시는 코어 외부에 위치해 있다.

캐시 메모리의 용량은 L1 < L2 < L3이고, 속도는 L3 < L2 < L1이다.

가격은 일반적으로 L3 > L2 > L1이다.

CPU가 메모리 내에 데이터가 필요하다고 판단하면 우선 L1캐시에 해당 데이터가 있는지를 알아보고 없다면, L2,L3 캐시 순으로 데이터를 검색한다.

멀티 코어 프로세서에서 L1-L2-L3 캐시는 일반적으로 그림과 같다.

L1,L2 캐시는 코어마다 고유하고, L3캐시는 여러 코어가 공유하는 형태로 사용된다.

![Untitled 6](https://user-images.githubusercontent.com/70310271/210796592-b85becd8-c932-420b-a10e-2aba75db20b7.png)

- 분리형 캐시 (Split Cache)

코어와 가장 가까운 L1 캐시는 조금이라도 접근속도를 빠르게 만들고 싶었다.

명령어만을 저장하는 L1캐시인 L1I 캐시

데이터만을 저장하는 L1캐시인 L1D캐시

이렇게 분리한 캐시를 분리형 캐시(Split Cache)라고 한다.

![Untitled 7](https://user-images.githubusercontent.com/70310271/210796627-7cfcd00a-f161-4f32-9aef-9a5f911ede16.png)

### 참조 지역성 원리(Locality of Reference)

Principle of Locality라고도 함.

캐시 메모리는 CPU가 사용할 법한 대상을 예측하여 저장한다.

자주 사용될 것으로 예측한 데이터가 실제로 들어맞아 캐시 메모리 내 데이터가 CPU에서 활용될 경우를 캐시 히트(Cache Hit)라고 한다.

반대로 자주 사용될 것으로 예측하여 캐시 메모리에 저장했지만, 예측이 틀려 메모리에서 필요한 데이터를 직접 가져와야 하는 경우를 캐시 미스(Cache miss)라고 한다.

캐시 미스가 발생하면 CPU가 필요한 데이터를 메모리에서 직접 가져와야하기 때문에 자주 발생하면 성능이 떨어진다.

- 캐시 적중률(Cache Hit Ratio) : 캐시가 히트되는 비율

```java
Cache Hit Ratio =  Number of Cache Hits  / (Number of Cache Hits + Number of Cache Misses)
```

우리가 사용하는 컴퓨터의 캐시 적중률은 대략 85~95% 이상이다.

CPU가 사용할 법한 데이터는 한가지 원칙으로 결정한다.

그게 바로 참조 지역성의 원리이다.

CPU가 메모리에 접근할 때의 주된 경향을 바탕으로 만들어진 원리이다.

1. CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향이 있다.
2. CPU는 접근한 메모리 공간 근처를 접근하려는 경향이 있다.

- 첫째. 최근에 접근했던 메모리에 다시 접근 하려는 경향

```java
import java.io.IOException;

public class Main {
    public static void main(String[] args) throws IOException {
        int n = 2;
        for(int i = 0 ; i < 9 ; i++){
            System.out.printf("%d X %d = %d\n", n, i, n*i);
        }
    }
}
```

쉽게 생각해서 구구단 코드를 보면 n이라는 변수를 계속해서 참조 할것이다.

이렇게 최근에 접근했던 메모리 공간에 다시 접근하는 경향을 “Temporal Locality”(시간 지역성)이라고 한다.

- 둘째. 접근한 메모리 공간 주변을 접근하려는 경향

일반적으로, 게임, 메모장, 브라우저는 각각 관련 데이터들이 모여 저장된다.

또한, 하나의 프로그램 내에서도 입력 기능, 출력 기능이 있다고 했을때, 각각의 기능과 관련한 데이터들을 모여서 저장된다.

![Untitled 8](https://user-images.githubusercontent.com/70310271/210796657-e6f391b9-4437-4fed-b1c5-4adccfeac6a6.png)

CPU가 메모장 프로그램을 실행할 적에는 워드 프로세서 프로그램이 모여 있는 공간 근처를 집중적으로 접근할 것이고, 사용자가 입력을 할 적에는 입력 기능이 모여있는 공간 근처를 집중적으로 접근할것이다.

이를 “Spatial Locality”(공간 지역성)이라고 한다.
