# 가상 메모리

메모리 내에 프로세스들이 연속적으로 배치되는 상황을 가정했다.

프로세스에 연속적인 메모리 공간을 할당하는 방식을 연속 메모리 할당 방식이라고 한다.

![Untitled](https://user-images.githubusercontent.com/70310271/213726874-9648a129-93d8-427d-b9c4-17dde0fdfa17.png)

프로세스들을 메모리에 연속적으로 할당할 때 무엇을 고려해야 하는지, 그리고 어떤 잠재적인 문제가 있는지 알아보자.

### 스와핑 (Swapping)

메모리에 적재된 프로세스들 중에는 현재 실행되지 않는 프로세스가 있을 수 있다.

입출력 작업의 요구로 대기 상태가 된 프로세스라던지, 오랫동안 사용되지 않은 프로세스가 이런 프로세스들에 속한다.

이러한 프로세스들을 임시로 보조기억장치 일부 영역으로 쫒아내고, 그렇게 해서 생긴 메모리상의 빈 공간에 또 다른 프로세스를 적재하여 실행하는 방식을 스와핑이라고 한다.

![Untitled 1](https://user-images.githubusercontent.com/70310271/213726921-d720855c-d1a7-41c4-a5a0-164882a00655.png)

이때 프로세스들이 쫒겨나는 보조기억장치의 일부 영역을 스왑 영역(Swap Space)라고 한다.

현재 실행되지 않는 프로세스가 메모리에서 스왑 영역으로 옮겨지는 것을 스왑 아웃(Swap-out)이라 한다.

반대로, 스왑 영역에 있던 프로세스가 다시 메모리로 옮겨 오는것을 스왑 인(Swap-in)이라 한다.

스왑 아웃 되었던 프로세스가 다시 스왑 인될 때는 스왑 아웃되기 전의 물리 주소와는 다른 주소에 적재될 수 있다.

스와핑을 이용하면 프로세스들이 요구하는 메모리 주소 공간의 크기가 실제 메모리 크기보다 큰 경우에도 프로세스들을 동시 실행할 수 있다.

![Untitled 2](https://user-images.githubusercontent.com/70310271/213726937-8ed68d79-020d-4253-a9a4-bab5173f438e.png)

Load Process D의 빈 부분에 외부 단편화가 발생한다.

feat) mac에서는 free, top 명령어를 통해 스왑 영역의 크기를 확인 할 수 있다.

<img width="653" alt="Screenshot_2022-12-16_at_7 41 29_PM" src="https://user-images.githubusercontent.com/70310271/213726976-99022054-eac1-45f2-8ee6-62dfd7dbea35.png">

### 메모리 할당

프로세스는 메모리 내의 빈 공간에 적재되어야 한다.

비어있는 메모리 공간에 프로세스를 연속적으로 할당하는 방식을 알아보자.

메모리 할당 방식에는 크게 3가지가 있다.

![Untitled 3](https://user-images.githubusercontent.com/70310271/213727012-c94a37d5-a831-43be-a28a-f3a875d99ff5.png)

1. 최초 적합(First Fit)

최초 적합은 운영체제가 메모리 내의 빈 공간을 순서대로 검색하다가 적재할 수 있는 공간을 발견하면 그 공간에 프로세스를 배치하는 방식이다.

운영체제가 A→B→C순서대로 검색했다면, A에 적재된다.

![Untitled 4](https://user-images.githubusercontent.com/70310271/213727045-7a187939-1ef4-4f09-918d-baab66c43921.png)

Process to Load 밑에 외부 단편화가 발생한다.

2. 최적 적합(Best Fit)

운영체제가 빈 공간을 모두 검색해 본 후, 프로세스가 적재될 수 있는 공간 중 가장 작은 공간에 프로세스를 배치하는 방식이다.

![Untitled 5](https://user-images.githubusercontent.com/70310271/213727067-8a653801-609a-40d2-b567-24120df630ba.png)

3. 최악 적합(Worst Fit)

운영체제가 빈 공간을 모두 검색해 본후, 프로세스가 적재될 수 있는 공간 중 가장 큰 공간에 프로세스를 배치하는 방식이다.

![Untitled 6](https://user-images.githubusercontent.com/70310271/213727135-70ae4b6f-9bbd-4ff9-a7aa-a38c188cab4e.png)

### 외부 단편화(External Fragmentation)

프로세스를 메모리에 연속적으로 배치하는 연속 메모리 할당은 언뜻 들으면 당연하게 느껴질 수 있지만, 사실 이는 메모리를 효율적으로 사용하는 방법이 아니다.

왜냐하면 연속 메모리 할당은 외부 단편화라는 문제를 내포하고 있기 때문이다.

![Untitled 7](https://user-images.githubusercontent.com/70310271/213727168-f41d8ad1-06d7-41ab-bd31-c4b5f283ea7f.png)

이렇게 메모리를 적재 해놓았다고 하자.

만약 프로세스 B와 D의 실행이 끝난다면, 빈공간이 생긴다.

![Untitled 8](https://user-images.githubusercontent.com/70310271/213727188-4e20d5c2-20ab-4f90-83a8-0fa0ff28045f.png)

이 상황에서 50MB크기의 프로세스를 적재할 수 있을까?

불가능하다. 빈 공간의 총합은 50MB일지라도, 빈 공간에도 50MB 크기의 프로세스가 적재될 수 없기 떄문이다.

프로세스들이 메모리에 연속적으로 할당되는 환경에서는 메모리 사이사이에 빈 공간들이 생긴다.

프로세스 바깥에 생기는 이러한 빈 공간들은 분명 빈 공간이지만 그 공간보다 큰 프로세스를 적재하기 어려운 상황을 초래하고, 이는 결국 메모리 낭비로 이어진다.

이러한 현상을 외부 단편화라고 한다.

앞의 예시는 간단하지만, 실제로는 프로세스에 적재되는 메모리의 용량도 크고, 많기 때문에 외부 단편화로 인해 낭비되는 공간은 더욱 크다.

`그렇기에 외부 단편화 문제는 반드시 해결해야한다.`

외부 단편화를 해결할 수 있는 대표적인 방안으로 메모리를 압축(Compaction)하는 방법이 있다. ( 우리가 메모리 조각 모음 버튼을 누르면 압축된다. )

![Untitled 9](https://user-images.githubusercontent.com/70310271/213727215-1c207a6a-c1fa-4b7c-94c7-93d0deb57145.png)

다만 압축 방식은 여러 단점이 있다.

작은 빈 공간들을 하나로 모으는 동안 시스템은 하던 일을 중지해야하고, 메모리에 있는 내용을 옮기는 작업은 많은 오버헤드를 야기하며, 어떤 프로세스를 어떻게 움직여야 오버헤드를 최소화하며 압축할 수 있는지에 대한 명확한 방법을 결정하기 어렵다.

이에 외부 단편화를 없앨 수 있는 또 다른 해결 방안이 등장했는데, 이것이 오늘날 까지도 사용되는 가상 메모리 기법, 그중 에서도 페이징 기법이 있다.

## 페이징을 통한 가상 메모리 관리

페이징은 현대 운영체제 메모리 관리 기법에 있어 가장 중요한 개념이다.

페이징이 왜 생겨 났으며 어떤 원리로 작동하는지 이해해 보자.

프로세스를 메모리에 연속적으로 할당하는 방식은 두 가지 문제를 내포하고 있다.

한가지는 앞선 절에서 다루었던 외부 단편화이고, 또 하나는 물리 메모리보다 큰 프로세스를 실행할 수 없다는 점이다.

프로세스를 반드시 메모리에 연속적으로 할당해야 한다면 메모리보다 큰 프로그램은 적재할 수 없다.

ex) 4GB메모리가 설치된 컴퓨터로는 4GB이상의 프로그램을 실행할 수 없다.

`가상 메모리는 실행하고자 하는 프로그램을 일부만 메모리에 적재하여 실제 물리 메모리크기 보다 더 큰 프로세스를 실행할 수 있게 하는 기술이다.`

이를 가능케 하는 가상 메모리 관리 기법에는 크게 페이징(Paging)과 세그멘테이션(Segmentation)이 있지만, 이 책에서는 현대 대부분의 운영체제가 사용하는 페이징 기법을 다룬다.

`페이징 기법을 이용하면 물리 메모리보다 큰 프로세스를 실행할 수 있을 뿐만 아니라 외부 단편화 문제도 해결할 수 있다.`

### 페이징(Paging)이란?

연속 메모리 할당 방식에서 외부 단편화가 생긴 근본적인 이유는 각기 다른 크기의 프로세스가 메모리에 연속적으로 할당되었기 때문이다.

만일 메모리와 프로세스를 일정한 단위로 자르고, 이를 메모리에 불연속적으로 할당할 수만 있다면 외부 단편화는 발생하지 않는다.

![Untitled 10](https://user-images.githubusercontent.com/70310271/213727257-8c7f6428-0a41-4c5a-8c14-3524ab45e764.png)

ex) 메모리 공간과 프로세스들을 10MB단위의 일정한 크기로 자르고, 잘린 메모리 조각들에 프로세스 조각들을 불연속적으로 적재한다면 외부 단편화는 발생하지 않는다.

페이징(Paging)은 프로세스 논리 주소 공간을 페이지(Page)라는 일정한 단위로 자르고, 메모리 물리 주소 공간을 프레임(Frame)이라는 페이지와 동일한 크기의 일정한 단위로 자른 뒤 페이지를 프레임에 할당하는 가상 메모리 관리 기법이다.

![Untitled 11](https://user-images.githubusercontent.com/70310271/213727276-7ae8ec25-b5f4-44c9-a7bb-060ac4a37f46.png)

Paging에서도 Swaping을 사용할 수 있다.

Paging을 사용하는 시스템에서는 프로세스 전체가 Swap Out/In 되는것이 아닌 페이지 단위로 Swap Out/In 된다.

즉, 메모리에 적재될 필요가 없는 페이지들은 보조 기억장치로 Swap-Out되고 실행에 필요한 페이지들은 Swap-In 된다.

메모리에 적재될 필요가 없는 페이지들은 보조기억장치로 Swap Out되고, 실행에 필요한 페이지들은 메모리로 Swap-In 되는것이다.

페이징 시스템에서는 Swap Out을 페이지 아웃(Page Out), Swap In을 페이지 인(Page In)이라고 부르기도 한다.

![Untitled 12](https://user-images.githubusercontent.com/70310271/213727295-e159fbe9-d31a-403c-884e-6ccbaa5334be.png)

한 프로세스를 실행하기 위해 프로세스 전체가 메모리에 적재될 필요가 없다.

프로세스를 이루는 페이지 중 실행에 필요한 일부 페이지만을 메모리에 적재하고,

당장 실행에 필요하지 않은 페이지들은 보조기억장치에 남겨둔다.

이와 같은 방식을 통해 물리 메모리보다 더큰 프로세스를 실행할 수 있다.

### 페이지 테이블(Page Table)

하지만 문제가 있다. 프로세스가 메모리에 불연속적으로 배치되어 있다면 CPU 입장에서 이를 순차적으로 실행할 수가 없다.

프로세스를 이루는 페이지가 어느 프레임에 적재되어 있는지 CPU가 모두 알고 있기 어렵기 떄문이다.

즉, 프로세스가 메모리에 불연속적으로 배치되면 CPU 입장에서 다음 실행할 명령어 위치를 찾기가 어려워 진다.

이를 해결하기위해 페이징 시스템은 프로세스가 비록 물리 주소에 불연속적으로 배치되더라도 논리 주소에는 연속적으로 배치되도록 페이지 테이블을 이용한다.

페이지 테이블은 페이지 번호와 프레임 번호를 짝지어주는 일종의 이정표이다.

CPU로 하여금 페이지 번호만 보고 해당 페이지가 적재된 프레임을 찾을 수 있게한다.

프로세스마다 각자의 프로세스 테이블이 있다.

![Untitled 13](https://user-images.githubusercontent.com/70310271/213727327-be34045c-8f40-4452-ab27-7591e1eecbd9.png)

물리 주소상에서는 프로세스들이 분산되어 저장되어 있더라도 CPU 입장에서 바라본 논리 주소는 연속적으로 보일 수 있다.

프로세스들이 메모리에 분산되어 저장되어 있더라도 CPU는 논리 주소를 그저 순차적으로 실행하면 된다.

![Untitled 14](https://user-images.githubusercontent.com/70310271/213727347-be845ecb-2961-40f2-bd1f-a6e5c9c77b3f.png)

- 내부 단편화( Internal Fragmentation)

페이징은 외부 단편화 문제를 해결할 수 있지만, 내부 단편화 문제를 야기할 수 있다.

페이징은 프로세스와 논리 주소 공간을 페이지라는 일정한 크기 단위로 자른다.

그런데 모든 프로세스가 페이지 크기에 딱 맞게 잘리는 것은 아니다.

다시 말해 모든 프로세스 크기가 페이지의 배수는 아니다.

![Untitled 15](https://user-images.githubusercontent.com/70310271/213727375-2e221f50-e7e8-4c20-8948-f5b68ecbd533.png)

ex) 페이지의 크기가 10KB인데, 프로세스의 크기가 108KB라고 한다면, 이 경우에는 마지막 페이지는 2KB만큼 크기가 남는다. 이러한 메모리 낭비를 내부 단편화라고 한다.

내부 단편화는 하나의 페이지 크기보다 작은 크기로 발생한다. 그렇기에 하나의 페이지 크기가 작다면 발생하는 내부 단편화의 크기는 작아질 것으로 기대할 수 있다.

하지만 하나의 페이지크기를 너무 작게 설정하면, 그 만큼 페이지 테이블의 크기도 커지기 때문에 페이지 테이블이 차지하는 공간이 낭비된다.

그렇기에 내부 단편화를 적당히 방지하면서 너무 크지 않은 페이지 테이블이 만들어지도록 페이지의 크기를 조정하는 것이 중요하다.

리눅스에서는 아래 명령어로 페이지 크기를 알아낼 수 있다.

```java
getconf PAGESIZE
```

<img width="644" alt="Screenshot_2022-12-17_at_4 45 43_PM" src="https://user-images.githubusercontent.com/70310271/213727404-21314c34-08cb-4f4e-b9fb-ca4f93feb9f1.png">

참고로 리눅스를 포함한 일부 운영체제에서는 위와 같이 기본적으로 설정된 페이지 크기보다 더 큰 크기의 페이지도 일부 허용하며 메모리에 유지하는 경우도 있다.

기본적으로 설정된 페이지보다 큰 페이지를 대형 페이지(Huge Page)라고 한다.

프로세스마다 각자의 프로세스들은 테이블을 가지고 있고, 각 프로세스의 페이지 테이블들은 메모리에 적재되어 있다.

그리고 CPU 내의 페이지 테이블 베이스 레지스터(PTBR : Page Table Base Register)는 각 프로세스의 페이지 테이블이 적재된 주소를 가리키고 있다.

프로세스 A가 실행될 때 PTBR은 A페이지 테이블을 가리키고, CPU는 프로세스 A 페이지 테이블을 통해 프로세스 A의 페이지가 적재된 프레임을 알 수 있다.

![Untitled 16](https://user-images.githubusercontent.com/70310271/213727450-2420ccee-ca83-4b4f-94fc-adb7d45bc24f.png)

`이러한 각 프로세스들의 페이지 테이블 정보들은 각 프로세스의 PCB에 기록된다.`

`그리고 프로세스의 문맥 교환이 일어날 때 다른 레지스터와 마찬가지로 함께 변경된다.`

그런데 이렇게 페이지 테이블을 메모리에 두면 문제가 생긴다.

`메모리 접근 시간이 두배로 늘어난다는 점이다.`

메모리에 있는 페이지 테이블을 보기 위해 한 번, 그렇게 알게 된 프레임에 접근하기

이와 같은 문제를 해결하기 위해 CPU 곁에(일반적으로 MMU 내에) TLB(Translation Lookaside Buffer)라는 페이지 테이블의 캐시 메모리를 둔다.

TLB는 페이지 테이블의 일부를 저장한다.

![Untitled 17](https://user-images.githubusercontent.com/70310271/213727476-d86d42e0-cb03-4694-b329-16f3ff624f2a.png)

CPU가 발생한 논리 주소에 대한 페이지 번호가 TLB에 있을 경우 이를 TLB 히트(TLB Hit)라고 한다.

이 경우에는 페이지가 적재된 프레임을 알기 위해 메모리에 접근할 필요가 없다.

그렇기에 메모리 접근을 한 번만 하면 된다.

하지만 만일 페이지 번호가 TLB에 없을 경우 어쩔 수 없이 페이지가 적재된 프레임을 알기 위해 메모리 내의 페이지 테이블에 접근하는 수 밖에 없다.

이를 TLB 미스(TLB Miss)라 한다.

### 페이징에서의 주소 변환

`하나의 페이지 혹은 프레임은 여러 주소를 포괄하고 있다.`

논리 주소 공간 0x00, 0x03까지 → 0페이지, 0x04~0x07 까지 → 1페이지

그렇기에 특정 주소에 접근하려면 2가지 정보가 필요하다.

1. 어떤 페이지 혹은 프레임에 접근하고 싶은지?
2. 접근하려는 주소가 그 페이지 혹은 프레임으로부터 얼마나 떨어져 있는지?

페이징 시스템에서는 모든 논리주소가 기본적으로 페이지 번호(Page Number)와 변위(Offset)로 이루어져 있다.

![Untitled 18](https://user-images.githubusercontent.com/70310271/213727506-6e4ec861-c8db-4aaa-984e-50f9f3c8f58c.png)

CPU가 32비트 주소를 내보냈다면 이 중 N비트는 페이지 번호, 32-N비트는 변위 이런식이 된다.

즉, 논리 주소 <페이지 번호, 변위> 는 페이지 테이블을 통해 <프레임 번호, 변위>로 변환된다.

![Untitled 19](https://user-images.githubusercontent.com/70310271/213727526-2a29d0f7-eb56-44f7-a791-7014faa6f52c.png)

논리 주소의 변위와 물리 주소의 변위 값은 같다.

![Untitled 20](https://user-images.githubusercontent.com/70310271/213727546-51203561-e118-48af-b76f-e73265d7c569.png)

구체적으로 논리주소 5번 페이지, 변위 2(<5,2>)에 접근한다고 가정하자.

5번 페이지는 1번 프레임에 있다. CPU는 1번 프레임에 변위 2부터 접근하기 떄문에, 0x04 주소에 +2를 더한, 0x06주소에 접근한다.

### 페이지 테이블 엔트리 (Page Table Entry ; PTE)

페이지 테이블을 조금 자세히 들여다 보자.

페이지 테이블의 각 행들을 페이지 테이블 엔트리라고 한다.

현재 까지 페이지 테이블 엔트리에 담기는 정보로 페이지 번호, 프레임 번호만을 설명했지만, 실은 페이지 테이블 엔트리에는 이외에도 다른 중요한 정보들이 있다.

1. 유효 비트 (Valid Bit)

현재 해당 페이지에 접근 가능한지 여부를 알려준다.

페이지 테이블 엔트리에서 프레임 번호 다음으로 중요한 정보라고도 볼 수 있다.

일반적으로 프로세스를 이루는 모든 페이지는 메모리에 있지 않다.

일부 페이지는 보조기억장치(스왑 영역)에 있는 경우가 많다.

유효 비트는 현재 페이지가 메모리에 적재되어 있는지, 보조기억장치에 있는지를 알려주는 비트이다.

![Untitled 21](https://user-images.githubusercontent.com/70310271/213727574-af29d576-2732-406e-9e81-ad2ee3f8221d.png)

메모리에 적재되어있다면 유효비트가 1이다.

메모리에 적재되어있지 않다면 유효비트가 0이다.

만일 CPU가 유효비트가 0인 메모리(적재되어 있지 않은 페이지)에 접근하려고 한다면 어떻게 될까?

이 경우 페이지 폴트(Page Fault)라는 예외(Exception)이 발생한다.

CPU가 페이지 폴트를 처리하는 과정은 하드웨어 인터럽트를 처리하는 과정과 유사하다.

1. CPU는 기존의 작업 내역을 백업한다.
2. 페이지 폴트 처리 루틴을 실행한다.
3. 페이지 처리 루틴은 원하는 페이지를 메모리로 가져온 뒤 유효 비트를 1로 변경해 준다.
4. 페이지 폴트를 처리했다면 이제 CPU는 해당 페이지에 접근할 수 있게 된다.

1. 보호 비트(Protection Bit)

페이지 보호 기능을 위해 존재하는 비트이다.

보호 비트를 통해 해당 페이지가 읽고 쓰기가 모두 가능한 페이지인지, 혹은 읽기만 가능한 페이지인지를 나타낼 수 있다.

![Untitled 22](https://user-images.githubusercontent.com/70310271/213727590-ceb23ca2-e15d-497b-beff-46c1c7831973.png)

페이지가 읽기만 가능한 페이지일때는 보호 비트가 0이다.

페이지가 읽고 쓰기가 모두 가능한 페이지일때는 보호 비트가 1이다.

앞서 프로세스를 이루는 요소 중 코드 영역은 읽기 전용 영역이라고했다.

이러한 읽기 전용 페이지에 쓰기를 시도하면 운영체제가 이를 막아준다.

이와 같은 방식으로 페이지들을 보호한다.

보호비트는 세 개의 비트로 조금 더 복잡하게 구현할 수도 있다.

r,w,x의 조합으로 읽기,쓰기, 실행 권한의 조합으로 나타낼수도 있다.

![Untitled 23](https://user-images.githubusercontent.com/70310271/213727614-70e28c67-c335-453f-923e-f614376068b6.png)

즉, 보호 비트는 페이지에 접근할 권한을 제한하여 페이지를 보호하는 비트이다.

2. 참조 비트 (Reference Bit)

CPU가 이 페이지에 접근한 적이 있는지 여부를 나타낸다.

적재 이후 CPU가 읽거나 쓴 페이지는 참조 비트가 1로 세팅된다.

적재 이후 한 번도 읽거나 쓴 적이 없는 페이지는 0으로 유지된다.

![Untitled 24](https://user-images.githubusercontent.com/70310271/213727638-735f0f65-571f-42f9-a913-02c2aadd450d.png)

3. 수정 비트(Modified Bit)

해당 페이지에 데이터를 쓴 적이 있는 지 없는지 수정 여부를 알려준다.

더티 비트(Dirty Bit)라고도 부른다.

변경된 적이 있는 페이지면 비트가 1이다.

변경된 적이 없는 페이지(한 번도 접근한 적 없가나 읽기만 했던 페이지)면 비트가 0이다.

왜 존재하는걸까?

수정 비트는 페이지가 메모리에서 사라질 때 보조기억장치에 쓰기 작업을 해야하는지, 할 필요가 없는지를 판단하기 위해 존재한다.

CPU는 메모리를 읽기도 하지만 메모리에 값을 쓰기도 한다.

CPU가 한 번도 접근하지 않았거나 읽기만 한 페이지의 경우 보조기억 장치에 저장된 해당 페이지의 내용과 메모리에 저장된 페이지 내용은 서로 같은 값을 가지고 있다.

![Untitled 25](https://user-images.githubusercontent.com/70310271/213727701-8078bc3c-1b59-4ae3-a57e-eee7bf841403.png)

`한번도 수정된적이 없는 페이지가 스왑 아웃될 경우 아무런 추가 작업 없이 새로 적재된 페이지로 덮어쓰기만 하면 된다.`

어차피 똑같은 페이지가 보조기억장치에 저장되어있기 때문이다.

하지만 CPU가 쓰기 작업을 수행한 페이지(수정 비트가 1인 페이지)의 경우 보조기억장치에 저장된 페이지의 내용과 메모리에 저장된 페이지의 내용은 서로 다른 값을 갖게된다.

이렇게 수정된 적이 있는 페이지가 스왑 아웃될 경우 변경된 값을 보조기억장치에 기록하는 작업이 추가되어야한다.

이 작업이 필요한 페이지인지 아닌지를 판단하기 위해 페이지 테이블 엔트리에 수정 비트를 두는 것이다.

많은 전공서는 지금까지 설명한 정도로만 페이지 테이블 엔트리를 설명하지만, 실제 페이지 테이블 엔트리에는 이외에도 다양한 정보가 있다.

[](https://github.com/kangtegong/self-learning-cs/blob/main/page_table/64-ia-32-architectures-software-developer-vol-3a-part-1-manual-p129.pdf)

페이지 테이블에 무엇이 저장되는지만 알아도 실제로 CPU가 메모리에 어떻게 접근하며 가상 메모리를 어떻게 다루는지 알 수 있다.

- 페이징의 이점 - 쓰기 시 복사

외부 단편화 문제를 해결한다는 점 이외에도 페이징이 제공하는 이점은 다양하다.

대표적인 것이 프로세스 간에 페이지를 공유할 수 있다는 점이다.

프로세스 간 페이지를 공유하는 사례로는 공유 라이브러리 등 다양하지만, 대표적인 예시로 쓰기 시 복사 (Copy on Write)가 있다.

앞서 10장에서 멀티 프로세스를 설명할때, 프로세스를 fork()하여 동일한 프로세스 두 개가 복제되면 코드 및 데이터 영역을 비롯한 모든 자원이 복제되어 메모리에 적재된다고 했다.

또한 프로세스를 통째로 메모리에 중복 저장하지 않으면서 프로세스끼리 자원을 공유하지 않는 방법도 있다고 했다.

전통적으로, 프로세스 간에는 기본적으로 자원을 공유하지 않는다.

즉, 부모 프로세스의 메모리 영역이 다른 영역에 자식 프로세스로서 복제되고, 각 프로세스의 페이지 테이블은 자신의 고유한 페이지가 할당된 프레임을 가리킨다.

`하지만 이 복사 작업은 프로세스 생성 시간을 늦출 뿐만 아니라 불필요한 메모리 낭비를 야기한다.`

![Untitled 26](https://user-images.githubusercontent.com/70310271/213727730-764a2b1d-9e65-4f15-a763-d643a83511d5.png)

쓰기 시 복사에서는 부모 프로세스와 동일한 프로세스가 생성되면 자식 프로세스로 하여금 부모 프로세스와 동일한 프레임을 가리킨다.

![Untitled 27](https://user-images.githubusercontent.com/70310271/213727751-251ed217-85c6-4c62-ac0c-d51b00a60423.png)

이로써 굳이 부모 프로세스의 메모리 공간을 복사하지 않고도 동일한 프레임을 가리킬 수 있다.

만일 부모 프로세스와 자식 프로세스가 메모리에 어떠한 데이터도 쓰지 않고 그저 읽기 작업만 이어 나간다면 이 상태가 지속된다.

그런데 프로세스 간에는 자원을 공유하지 않는다.

부모 프로세스 혹은 자식 프로세스 둘 중 하나가 페이지에 쓰기 작업을 하면 그 순간 해당 페이지가 별도의 공간으로 복제된다.

각 프로세스는 자신의 고유한 페이지가 할당된다.

![Untitled 28](https://user-images.githubusercontent.com/70310271/213727773-7295964e-0802-445b-9c56-4c3a0bf7407c.png)

이것이 쓰기 시 복사이다.

이러한 쓰기시 복사를 통해 프로세스 생성 시간을 줄이는 것은 물론 메모리 공간 절약도 가능하다.

- 계층적 페이징(Hierarchical Paging)

페이지 테이블의 크기는 생각보다 작지 않다.

프로세스의 크기가 커지면 자연히 프로세스 테이블의 크기도 커지기 때문에 프로세스를 이루는 모든 페이지 테이블 엔트리를 메모리에 두는 것은 큰 메모리 낭비이다.

이에 프로세스를 이루는 모든 페이지 테이블 엔트리를 항상 메모리에 유지하지 않을 수 있는 방법이 등장했는데, 이것이 계층적 페이징이다.

`계층적 페이징은 페이지 테이블을 페이징하여 여러 단계의 페이지를 두는 방식이다.`

여러 단계의 페이지를 둔다는 점에서 다단계 페이지 테이블(Multi-Level Page Table)기법이라도고 한다.

![Untitled 29](https://user-images.githubusercontent.com/70310271/213727791-7fe57b23-c2e9-4acb-8144-34c6f8e4f991.png)

가장 먼저 페이지 테이블을 여러 개의 페이지로 쪼개고, 이 페이지들을 가리키는 페이지 테이블(Outer Page Table)을 두는 방식이 계층적 페이징이다.

페이지 테이블을 이렇게 계층적으로 구성하면 모든 페이지 테이블을 항상 메모리에 유지할 필요가 없다.

페이지 테이블들 중 몇 개는 보조 기억장치에 있어도 무방하며, 추후 해당 페이지 테이블을 참조해야 할 때가 있으면 그때 메모리에 적재하면 그만이다.

막대한 크기의 페이지 테이블로 인해 낭비되는 공간을 줄일 수 있다.

feat) CPU와 가장 가까이 위치한 페이지 테이블(Outer Page Table)은 항상 메모리에 유지해야한다.

계층적 페이징을 사용하는 경우 CPU가 발생하는 논리 주소도 달라진다.

계층적 페이징을 사용하지 않을 경우 논리 주소는 <페이지 번호, 변위>로 만들어진다.

하지만 계층적 페이징을 이용하는 환경에서의 논리주소는 <바깥 페이지 번호, 안쪽 페이지 번호, 변위>이렇게 만들어진다.

바깥 페이지 번호에 해당하는 항목은 CPU와 근접한 곳에 위치한(Outer Page Table) 페이지 테이블 엔트리를 가리킨다.

안쪽 페이지 번호는 페이지 테이블의 페이지 번호를 가리킨다.

이러한 논리 주소를 토대로 주소 변환은 아래와 같이 이루어진다.

1. 바깥 페이지 번호를 통해 페이지 테이블의 페이지 찾기
2. 페이지 테이블의 페이지를 통해 프레임 번호를 찾고 변위를 더함으로서 물리 주소 얻기

![Untitled 30](https://user-images.githubusercontent.com/70310271/213727806-c654a07a-5c6a-46b7-b47b-ac84c1360da3.png)

페이지 테이블의 계층은 3개, 4개 그이상의 계층으로도 구성될 수 있다.

다만 페이지 테이블의 계층이 늘어날수록 페이지 폴트가 발생했을 경우 메모리 참조 횟수가 많아지므로 계층이 많다고 해서 반드시 좋다고 볼 수는 없다.

## 페이지 교체와 프레임 할당

앞에선 페이징의 개념을 배웠고 이제는 운영체제가 수 많은 페이지를 어떻게 관리하는지 알아보자.

운영체제는 프로세스들이 한정된 메모리를 효율적으로 이용할 수 있도록 기존에 메모리에 적재된 불필요한 페이지를 선별하여 보조 기억장치로 내보낼 수 있어야하고, 프로세스들에 적절한 수의 프레임을 할당하여 페이지를 할당할 수 있게 해야한다.

### 요구 페이징 (Demand Paging)

프로세스를 메모리에 적재할 때 처음부터 모든 페이지를 적재하지 않고 필요한 페이지만을 메모리에 적재하는 기법을 요구 페이징이라고한다.

`실행에 요구되는 페이지만 적재하는 기법`

- 요구 페이징 알고리즘
1. CPU가 특정 페이지에 접근하는 명령어를 실행한다.
2. 해당 페이지가 현재 메모리에 있을 경우(유효 비트가 1일 경우) CPU는 페이지가 적재된 프레임에 접근한다.
3. 해당 페이지가 현재 메모리에 없을 경우(유효 비트가 0일 경우) 페이지 폴트가 발생한다.
4. 페이지 폴트 처리 루틴은 해당 페이지를 메모리로 적재하고 유효비트를 1로 설정한다.
5. 다시 1번을 수행한다.

참고로 아무런 페이지도 메모리에 적재하지 않은 채 무작정 실행부터 할 수도 있다.

이 경우 프로세스의 첫 명령어를 실행하는 순간부터 페이지 폴트가 계속 발생하게 되고, 실행에 필요한 페이지가 어느 정도 적재된 이후부터는 페이지 폴트 발생 빈도가 떨어진다.

이를 순수 요구 페이징(Pure Demand Paging) 기법이라 한다.

요구 페이징 시스템이 안정적으로 작동하려면 필연적으로 2가지를 해결해야한다.

1. 페이지 교체

요구 페이징 기법으로 페이지들을 적재하다 보면 언젠가 메모리가 가득차게 된다.

이때는 당장 실행에 필요한 페이지를 적재하기 위해 메모리에 적재된 페이지를 보조기억장치로 내보내야 한다.

`이때 메모리에 적재된 많은 페이지 중 어떤 페이지를 내보내는것이 최선일까.`

이를 결정하는 알고리즘이 페이지 교체 알고리즘이다.

### 페이지 교체 알고리즘

일반적으로 페이지 폴트를 가장 적게 일으키는 알고리즘을 좋은 알고리즘으로 평가한다.

페이지 폴트가 일어나면 보조기억장치로부터 필요한 페이지를 가져와야하기 때문에 메모리에 적재된 페이지를 가져오는것보다 느려지기 때문이다.

그렇기에 페이지 교체 알고리즘을 제대로 이해하려면 페이지 폴트 횟수를 알 수 있어야한다.

그리고 페이지 폴트 횟수는 페이지 참조열(Page Reference String)을 통해 알 수 있다.

페이지 참조열의 개념은 CPU가 참조하는 페이지들 중 연속된 페이지를 생략한 페이지열을 의미한다.

```java
ex)
CPU가 페이지에 접근한 순서 : 2 2 2 3 5 5 5 3 3 7
페이지 참조열 : 2 3 5 3 7
```

연속된 페이지를 생략하는 이유는 중복된 페이지를 참조하는 행위는 페이지 폴트를 발생시키지 않기 때문이다.

`페이지 교체 알고리즘을 평가할 때 관심있게 고려할 것은 오직 페이지 폴트의 발생횟수이다.`

대표적인 페이지 교체 알고리즘에 대해 알아보자.

1. FIFO 페이지 교체 알고리즘(Firist In First Out Page Replacement Algorithm)

가장 단순한 방법이다. 이름 그대로 메모리에 가장 먼저 올라온 페이지부터 내쫒는 방식이다.

ex) 프로세스가 사용할 수 있는 프레임이 3개 있다고 가정하고 페이지 참조열이 아래와 같다.

```java
페이지 참조열 : 2 3 1 3 5 2 3 4 2 3
```

![Untitled 31](https://user-images.githubusercontent.com/70310271/213727891-a23daf4f-0a0e-44a7-b481-ad5cc6f8abb0.png)

딱 봐도 FIFIO 페이지 교체 알고리즘은 아이디어와 구현이 간단하지만, 좋은 알고리즘은 아니다.

프로그램 실행 초기에 적재된 페이지 속에는 프로그램 실행 초기에 잠깐 실행되다가 이후에 사용되지 않을 페이지도 있지만, 프로그램 실행 내내 사용될 내용을 포함하고 있을 수도 있기 때문이다.

- 2차 기회 페이지 교체 알고리즘(Second Change Page Replacement Algorithm)

FIFO 페이지 교체 알고리즘은 자주 참조되는 페이지가 먼저 적재되었다는 이유만으로 내쫓길 수 있다는 문제가 있다.

2차 기회 페이지 교체 알고리즘은 이러한 부작용을 어느 정도 개선한 FIFO 페이지 교체 알고리즘의 변형이다.

이름 그대로 한 번 더 기회를 주는 알고리즘이다.

메모리에 가장 오래 머물렀다고 할지라도 참조 비트가 1이라는 의미는 CPU가 접근한 적이 있다는 의미이므로 한번의 기회를 더 주는 셈이다.

참조 비트가 1일 경우, 당장 내쫓지 않고 참조 비트를 0으로 만든뒤 현재 시간을 적재 시간으로 설정한다.

메모리에 가장 오래 머무른 페이지의 참조 비트가 0일 경우 이 페이지는 가장 오래된 페이지 이면서 동시에 사용되지않는 페이지라고 볼 수 있으므로 보조기억장치로 내보내면 된다.

ex) 5개의 프레임을 가진 메모리, 3,1,5,2,4 순으로 적재, 및 참조비트

![Untitled 32](https://user-images.githubusercontent.com/70310271/213727925-a01793c7-8c68-41f9-b816-6c864f79b115.png)

Page 6이 새로 적재되어야한다면, Page 3의 참조 비트를 0으로 바꾸고 최근에 적재된 페이지로 간주한다.

![Untitled 33](https://user-images.githubusercontent.com/70310271/213727942-4fa2e9b4-bb9f-475f-9595-9a34841f2e01.png)

가장 오래된 페이지인 Page 1을 내보내고 Page 1이 적재되었던 프레임에 Page 6을 적재하면 된다.

![Untitled 34](https://user-images.githubusercontent.com/70310271/213727972-ac7742f9-9d73-4443-8c5b-4a25eaf73027.png)

1. 최적 페이지 교체 알고리즘

CPU에 의해 참조되는 횟수를 고려하는 페이지 교체 알고리즘이다.

보조기억장치로 내보내야 할 페이지는 앞으로 사용 빈도가 가장 낮은 페이지이므로, 앞으로의 사용 빈도가 가장 낮은 페이지를 교체하는 알고리즘이다.

![Untitled 35](https://user-images.githubusercontent.com/70310271/213728007-8320a447-ad81-42fa-ac42-60c544ae548b.png)

이름 그대로 가장 낮은 페이지 폴트율을 보장하는 알고리즘이다.

다른 페이지 참조열을 바탕으로 실험해 보아도 타 페이지 교체 알고리즘에 비해 페이지 폴트 발생 빈도가 가장 낮다.

다만, 최적 페이지 교체 알고리즘은 실제 구현이 어렵다.

“앞으로 오랫동안 사용되지 않을 페이지”를 예측하기란 어렵기 때문이다.

프로세스가 앞으로 메모리 어느 부분을 참조할지 미리 알아야하는데, 이는 현실적으로 불가능에 가깝다.

그래서 이 알고리즘은 운영체제에서 사용하기보다는, 주로 다른 페이지 교체 알고리즘의 이론상 성능을 평가하기 위한 목적으로 사용된다.

최적 페이지 교체 알고리즘을 실행했을 때 발생하는 페이지 폴트 횟수를 페이지 폴트의 하한선으로 간주하고, 최적 페이지 교체 알고리즘에 비해 얼만큼 페이지 폴트 횟수가 발생하느냐를 통해 페이지 교체 알고리즘을 평가하기 위해 사용한다.

- LRU 페이지 교체 알고리즘 (Least Recently Used Page Replacement Algorithm)

최적 페이지 교체 알고리즘과 비슷한 알고리즘이다.

가장 오랫동안 사용되지 않은 페이지를 교체하는 알고리즘이다.

최근에 사용되지 않은 페이지는 앞으로도 사용되지 않을 것 이라는 아이디어를 토대로 만들어진 알고리즘이다.

![Untitled 36](https://user-images.githubusercontent.com/70310271/213728040-3bad7252-20be-4cab-be68-d4ed69f5e8bc.png)

이외에도 페이지 교체 알고리즘은 매우 다양하다.

LRU 교체 알고리즘만 하더라도 많은 파생 알고리즘이 있다.

대표적인 페이지 교체 알고리즘들의 기본적인 아이디어는 무엇인지를 이해하는데에 중점을 두자.

1. 프레임 할당

### 스래싱(Thrashing)과 프레임 할당

페이지 폴트가 자주 발생하는 이유에 나쁜 페이지 교체 알고리즘만 있는건 아니다.

프로세스가 사용할 수 있는 프레임 수가 적어도 페이지 폴트는 자주 발생한다.

반대로 프로세스가 사용할 수 있는 프레임 수가 많으면 일반적으로 페이지 폴트 빈도는 감소한다.

이 문제가 앞의 알고리즘보다 더 근본적인 이유이다.

![Untitled 37](https://user-images.githubusercontent.com/70310271/213728064-fa2dfe80-48d1-4fc0-8399-bb872952351e.png)

이처럼 프레임이 부족하면 CPU는 페이지 폴트가 자주 발생할 수 밖에 없다.

CPU가 쉴새 없이 프로세스를 실행해야 컴퓨터 전체의 생산성도 올라갈텐데, 페이지 교체에 너무 많은 시간을 쏟으면 당연히 성능에도 큰 악영향이 초래된다.

`이처럼 프로세스가 실제 실행되는 시간보다 페이징에 더 많은 시간을 소요하여 성능이 저하되는 문제를 스래싱이라고한다.`

지나치게 빈번한 페이지 교체로 인해 CPU 이용률이 낮아지는 문제를 뜻한다.

메모리에서 동시 실행되는 프로세스의 수를 다중프로그래밍의 정도 (Degree Of Multiprogramming)이라고 한다.

다중프로그래밍의 정도가 높다면 현재 메모리에는 많은 프로세스가 동시에 실행 중이고, 낮다면 현재 메모리에는 적은 프로세스가 동시에 실행중이라고 이해하면된다.

![Untitled 38](https://user-images.githubusercontent.com/70310271/213728084-c2ef87f5-a69a-4c21-b0b4-6643701dc3db.png)

이 그래프는 동시에 실행되는 프로세스 수를 늘린다고 해서 CPU 이용률이 그에 비례해서 증가하는것이 아님을 나타낸다.

동시에 실행되는 프로세스 수가 어느 정도 증가하면 CPU이용률이 높아지지만, 필요 이상으로 늘리면 각 프로세스들이 사용할 수 있는 프레임 수가 적어지기 때문에 페이지 폴트가 지나치게 빈번히 발생한다.

이에 따라 CPU 이용률이 떨어져 전체적인 성능이 저하되는것이다.

아무리 CPU의 성능이 뛰어나도 동시에 실행되는 프로세스를 수용할 물리 메모리가 너무 작다면 전체 컴퓨터의 성능이 안좋아 지는 이유가 이때문이다.

Thrashing이 발생하는 근본적인 원인은 각 프로세스가 필요로 하는 최소한의 프레임 수가 보장되지 않았기 때문이다.

ex) 프로세스 A를 무리없이 실행하기 위해서는 최소 10개의 프레임이 필요한데,

프로세스 A가 다섯개의 프레임만 이용할 수 있다면 이 프로세스는 페이지 폴트가 자주 발생한다.

그렇기에 운영체제는 각 프로세스들이 무리 없이 실행하기 위한 최소한의 프레임 수를 파악하고 프로세스들에 적절한 수만큼 프레임을 할당해 줄 수 있어야한다.

우선 가장 단순한 형태의 프레임 할당 방식부터 알아보자.

- 균등할당(Equal Allocation)

ex) 3개의 프로세스에 총 300개의 프레임을 할당할 수 있다면 각 프로세스에 100개의 프레임을 할당하는 방식이다.

이러한 프레임 할당 방식을 균등 할당이라고 한다.

실행되는 프로세스들의 크기는 각기 다른데, 동일한 프레임 개수를 할당하는것은 비합리적이다.

- 비례 할당(Proportional Allocation)

ex)상대적으로 크기가 큰 워드 프로세스에는 더 많이 프레임을 할당해주고, 상대적으로 작은 메모장에는 적은 프레임을 할당하는것이 더 합리적이다.

이렇게 프로세스의 크기가 크면 프레임을 많이 할당하고 프로세스 크기가 작으면 프레임을 적게 나눠주는 방식을 비례 할당이라고 한다.

균등 할당과 비례 할당 방식은 프로세스의 실행 과정을 고려하지 않고 단순히 프로세스의 크기와 물리 메모리의 크기만을 고려한 방식이라는 점에서 정적 할당 방식(Static Allocation)이라고 한다.

하지만 비례 할당 또한 완벽한 방식이 아니다.

프로세스의 크기가 클지라도 막상 실행해보면 많은 프레임을 필요로 하지 않는 경우도 있다.

반대로 프로세스의 크기가 작아도 실행해 보니 많은 프레임을 필요로 하는 경우도 있다.

즉, 하나의 프로세스가 실제로 얼마나 많은 프레임이 필요한지는 결국 실행해 봐야 아는 경우가 많다.

프로세스를 실행하는 과정에서 배분할 프레임을 결정하는 방식에는 크게 2가지가 있다. 이 두 개의 방식은 프로세스의 실행을 보고 할당 프레임 수를 결정한다는 점에서 동적 할당 방식이라고 한다.

1. 작업 집합 모델(Working Set Model)

스래싱이 발생하는 이유는 빈번한 페이지 교체 때문이다.

작업 집합 모델 기반 프레임 할당 방식은 프로세스가 일정 기간 동안 참조한 페이지 집합을 기억하여 빈번한 페이지 교체를 방지한다.

CPU가 메모리를 참조할때에는 참조 지역성의 원리에 의거해 주로 비슷한 구역을 집중적으로 참조한다.

한 프로세스가 100개의 페이지로 이루어졌다고 해서 100개를 모두 고르게 참조하는것이 아니라, 특정 시간 동안에는 몇 개의 페이지 내 주소들 만을 집중적으로 참조한다.

CPU가 특정 시간 동안 주로 참조한 페이지 개수만큼만 프레임을 할당하면 페이지 교체는 빈번하게 발생하지 않는다.

ex1) CPU가 어떤 프로세스를 실행하는 동안 3초에 7개의 페이지를 집중적으로 참조했다면 운영체제는 그 프로세스를 위해 그 순간 만큼은 최소 7개의 프레임을 할당하면 된다.

ex2) CPU가 어떤 프로세스를 실행하는 동안 3초에 20개의 페이지를 집중적으로 참조했다면 운영체제는 그 프로세스를 위해 그 순간만큼은 최소 20개의 프레임을 할당하면 된다.

실행 중인 프로세스가 일정 시간 동안 참조한 페이지의 집합을 작업 집합(Working Set)이라고 한다.

CPU가 과거에 주로 참조한 페이지를 작업 집합에 포함한다면 운영체제는 작업 집합의 크기만큼만 프레임을 할당하면 된다.

- 작업 직합을 구해보자.

작업 집합을 구하기 위해서는 2가지가 필요하다

1. 프로세스가 참조한 페이지
2. 일정 시간 간격

ex) 참조한 페이지와 시간간격은 7이라고 가정해보자.

![Untitled 39](https://user-images.githubusercontent.com/70310271/213728121-e1d0db78-0e87-4bcd-b131-4cfd63d45715.png)

이 프로세스는 시간 t1에 최소 3개의 프레임이 필요하다고 볼 수 있다.

![Untitled 40](https://user-images.githubusercontent.com/70310271/213728140-b8d79c6e-a037-465b-b2a8-c754ee4fac40.png)

이 프로세스는 시간 t2에 최소 5개의 프레임이 필요하다고 볼 수 있다.

1. 페이지 폴트 빈도(Page-Fault Frequency)

페이지 폴트 빈도를 기반으로 한 프레임 할당은 2개의 가정에서 생겨난 아이디어이다.

1. 페이지 폴트율이 너무 높으면 그 프로세스는 너무 적은 프레임을 갖고 있다.
2. 페이지 폴트율이 너무 낮으면 그 프로세스가 너무 많은 프레임을 갖고 있다.

![Untitled 41](https://user-images.githubusercontent.com/70310271/213728164-52519a96-1505-43bf-b8bf-11a2e1e83502.png)

만일 페이지 폴트율이 상한선 보다 더 높아지면 너무 적은 프레임을 갖고 있는것이다.

페이지 폴트율이 하한선 보다 더 낮아지면 그 프로세스는 너무 많은 프레임을 갖고 있다고 볼 수 있다.

이경우 다른 프로세스에 할당하기 위해 프레임을 회수한다.

페이지 폴트 빈도 기반 프레임 할당 방식은 페이지 폴트율에 상한선과 하한선을 정하고, 이 범위 안에서만 프레임을 할당하는 방식이다.
